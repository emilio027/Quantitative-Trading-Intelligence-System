# Quantitative Trading Intelligence System
## Deployment Guide

### Version 2.0.0 Enterprise
### Author: DevOps Engineering Team
### Date: August 2025

---

## Overview

This deployment guide provides comprehensive instructions for deploying the Quantitative Trading Intelligence System across development, staging, and production environments. The system requires ultra-low latency infrastructure with sub-millisecond performance requirements for institutional-grade algorithmic trading.

## Prerequisites

### Infrastructure Requirements

**Minimum Production Requirements**:
- CPU: 32 cores (Intel Xeon Platinum 8000 series) with AVX-512
- RAM: 256GB DDR4-3200 ECC memory
- Storage: 4TB NVMe SSD with RAID 0 configuration
- Network: 40Gbps with RDMA/InfiniBand support
- GPU: 4Ã— NVIDIA V100 or A100 for ML acceleration
- OS: Ubuntu 22.04 LTS or RHEL 9

**High-Frequency Trading Requirements**:
- Latency: <100 microseconds to exchange feeds
- Co-location: Direct exchange connectivity preferred
- Kernel Bypass: DPDK or similar for network acceleration
- CPU Isolation: Dedicated cores for critical trading threads
- Real-Time OS: Linux RT kernel for deterministic performance

### Software Dependencies

- **Container Runtime**: Docker 24.0+ with containerd
- **Orchestration**: Kubernetes 1.28+ with custom schedulers
- **Message Queue**: Apache Kafka 3.0+ with custom partitioning
- **Databases**: PostgreSQL 15+, InfluxDB 2.0+, Redis 7+
- **ML Runtime**: TensorFlow 2.13+, PyTorch 2.0+, CUDA 12.0+
- **Monitoring**: Prometheus, Grafana, Jaeger for observability

## Local Development Setup

### 1. Environment Setup

```bash
# Clone repository
git clone https://github.com/enterprise/quantitative-trading-system.git
cd quantitative-trading-system

# Create development environment
python3.11 -m venv trading_env
source trading_env/bin/activate

# Install dependencies with performance optimizations
pip install -r requirements.txt
pip install -r requirements-dev.txt

# Install GPU support (if available)
pip install tensorflow[and-cuda]==2.13.0
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

### 2. Database Configuration

```bash
# PostgreSQL setup for market data
sudo apt install postgresql-15 postgresql-contrib
sudo systemctl start postgresql

# Create trading database
sudo -u postgres createdb trading_intelligence
sudo -u postgres psql trading_intelligence
```

```sql
-- Database optimization for trading
ALTER SYSTEM SET shared_buffers = '16GB';
ALTER SYSTEM SET effective_cache_size = '48GB';
ALTER SYSTEM SET maintenance_work_mem = '4GB';
ALTER SYSTEM SET checkpoint_completion_target = 0.9;
ALTER SYSTEM SET wal_buffers = '64MB';
ALTER SYSTEM SET random_page_cost = 1.1;
ALTER SYSTEM SET seq_page_cost = 1.0;

-- Restart PostgreSQL
\q
sudo systemctl restart postgresql
```

### 3. InfluxDB Setup (Time Series Data)

```bash
# Install InfluxDB 2.0
wget -qO- https://repos.influxdata.com/influxdb.key | sudo apt-key add -
source /etc/lsb-release
echo "deb https://repos.influxdata.com/${DISTRIB_ID,,} ${DISTRIB_CODENAME} stable" | sudo tee /etc/apt/sources.list.d/influxdb.list
sudo apt update && sudo apt install influxdb2

# Configure for high-frequency data
sudo systemctl start influxdb
influx setup --force \
  --username admin \
  --password SecurePassword123 \
  --org trading-enterprise \
  --bucket market-data \
  --retention 365d
```

### 4. Apache Kafka Setup

```bash
# Download and setup Kafka
wget https://downloads.apache.org/kafka/2.13-3.5.0/kafka_2.13-3.5.0.tgz
tar -xzf kafka_2.13-3.5.0.tgz
cd kafka_2.13-3.5.0

# Configure for low-latency
cat >> config/server.properties << EOF
# Performance optimizations
num.network.threads=16
num.io.threads=16
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
log.segment.bytes=1073741824
log.retention.hours=168
log.cleanup.policy=delete
compression.type=lz4
EOF

# Start Kafka
bin/zookeeper-server-start.sh config/zookeeper.properties &
bin/kafka-server-start.sh config/server.properties &
```

### 5. Environment Configuration

```bash
# Create .env file
cat > .env << EOF
# Database Configuration
DATABASE_URL=postgresql://trading:password@localhost:5432/trading_intelligence
INFLUXDB_URL=http://localhost:8086
INFLUXDB_TOKEN=your-influxdb-token
INFLUXDB_ORG=trading-enterprise
INFLUXDB_BUCKET=market-data

# Message Queue
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_SECURITY_PROTOCOL=PLAINTEXT

# Redis Configuration
REDIS_URL=redis://localhost:6379/0
REDIS_CLUSTER_NODES=localhost:7001,localhost:7002,localhost:7003

# Trading Configuration
TRADING_MODE=DEVELOPMENT
PAPER_TRADING=true
MAX_POSITION_SIZE=100000
RISK_LIMIT_ENABLED=true

# ML Configuration
MODEL_PATH=./models
FEATURE_STORE_PATH=./data/features
GPU_ENABLED=true
BATCH_SIZE=32
LEARNING_RATE=0.001

# Market Data
BLOOMBERG_API_KEY=your-bloomberg-key
IEX_API_KEY=your-iex-key
ALPHA_VANTAGE_KEY=your-alpha-vantage-key
POLYGON_API_KEY=your-polygon-key

# Security
JWT_SECRET_KEY=your-jwt-secret-32-characters
ENCRYPTION_KEY=your-encryption-key-32-chars
SSL_CERT_PATH=./ssl/cert.pem
SSL_KEY_PATH=./ssl/key.pem

# Monitoring
PROMETHEUS_ENABLED=true
GRAFANA_ENABLED=true
JAEGER_ENABLED=true
LOG_LEVEL=INFO
METRICS_PORT=9090
EOF
```

### 6. Start Development Environment

```bash
# Start all services
python scripts/start_dev_environment.py

# Verify system health
curl http://localhost:8000/health
curl http://localhost:9090/metrics
```

## Docker Deployment

### 1. Optimized Dockerfile

```dockerfile
# Multi-stage build for production optimization
FROM nvidia/cuda:12.1-devel-ubuntu22.04 AS builder

# Install system dependencies
RUN apt-get update && apt-get install -y \
    python3.11 python3.11-dev python3-pip \
    gcc g++ cmake \
    libopenblas-dev \
    libomp-dev \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Copy requirements and install dependencies
COPY requirements.txt requirements-prod.txt ./
RUN pip3.11 install --no-cache-dir -r requirements-prod.txt

# Production stage
FROM nvidia/cuda:12.1-runtime-ubuntu22.04 AS production

# Install runtime dependencies
RUN apt-get update && apt-get install -y \
    python3.11 \
    libopenblas-base \
    libomp5 \
    curl \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Create non-root user for security
RUN groupadd -r trading && useradd -r -g trading trading

# Copy Python environment from builder
COPY --from=builder /usr/local/lib/python3.11 /usr/local/lib/python3.11
COPY --from=builder /usr/local/bin /usr/local/bin

# Copy application code
COPY --chown=trading:trading Files/ ./Files/
COPY --chown=trading:trading models/ ./models/
COPY --chown=trading:trading config/ ./config/
COPY --chown=trading:trading *.py ./

# Set environment variables
ENV PYTHONPATH=/app
ENV PYTHONUNBUFFERED=1
ENV CUDA_VISIBLE_DEVICES=0,1,2,3
ENV OMP_NUM_THREADS=16
ENV MKL_NUM_THREADS=16

# Performance optimizations
ENV MALLOC_ARENA_MAX=2
ENV MALLOC_MMAP_THRESHOLD=131072
ENV MALLOC_TRIM_THRESHOLD=131072

# Switch to non-root user
USER trading

# Health check
HEALTHCHECK --interval=10s --timeout=5s --start-period=30s --retries=3 \
  CMD curl -f http://localhost:8000/health || exit 1

# Expose ports
EXPOSE 8000 9090

# Start application with optimizations
CMD ["python3.11", "-O", "-m", "gunicorn", \
     "--bind", "0.0.0.0:8000", \
     "--workers", "4", \
     "--worker-class", "uvicorn.workers.UvicornWorker", \
     "--worker-connections", "1000", \
     "--max-requests", "10000", \
     "--max-requests-jitter", "1000", \
     "--timeout", "30", \
     "--preload", \
     "app:app"]
```

### 2. Docker Compose for Development

```yaml
version: '3.8'

services:
  trading-app:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    ports:
      - "8000:8000"
      - "9090:9090"
    environment:
      - DATABASE_URL=postgresql://trading:password@postgres:5432/trading_intelligence
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - REDIS_URL=redis://redis:6379
      - GPU_ENABLED=true
    volumes:
      - ./models:/app/models
      - ./data:/app/data
      - ./logs:/app/logs
    depends_on:
      - postgres
      - redis
      - kafka
      - influxdb
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped

  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: trading_intelligence
      POSTGRES_USER: trading
      POSTGRES_PASSWORD: password
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./config/postgres.conf:/etc/postgresql/postgresql.conf
    command: postgres -c config_file=/etc/postgresql/postgresql.conf
    ports:
      - "5432:5432"
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes --maxmemory 8gb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    restart: unless-stopped

  influxdb:
    image: influxdb:2.7-alpine
    environment:
      DOCKER_INFLUXDB_INIT_MODE: setup
      DOCKER_INFLUXDB_INIT_USERNAME: admin
      DOCKER_INFLUXDB_INIT_PASSWORD: SecurePassword123
      DOCKER_INFLUXDB_INIT_ORG: trading-enterprise
      DOCKER_INFLUXDB_INIT_BUCKET: market-data
    volumes:
      - influxdb_data:/var/lib/influxdb2
    ports:
      - "8086:8086"
    restart: unless-stopped

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_LOG_CLEANUP_POLICY: delete
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_COMPRESSION_TYPE: lz4
    volumes:
      - kafka_data:/var/lib/kafka/data
    ports:
      - "9092:9092"
    depends_on:
      - zookeeper
    restart: unless-stopped

  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
    restart: unless-stopped

  prometheus:
    image: prom/prometheus:latest
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    ports:
      - "9091:9090"
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana:/etc/grafana/provisioning
    ports:
      - "3000:3000"
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
  influxdb_data:
  kafka_data:
  zookeeper_data:
  prometheus_data:
  grafana_data:
```

## Kubernetes Deployment

### 1. High-Performance Node Configuration

```yaml
# gpu-node-pool.yaml
apiVersion: v1
kind: Node
metadata:
  name: trading-gpu-node-001
  labels:
    node-type: trading-gpu
    performance-tier: ultra-high
spec:
  capacity:
    cpu: "32"
    memory: "256Gi"
    nvidia.com/gpu: "4"
    ephemeral-storage: "4Ti"
  nodeInfo:
    kernelVersion: "5.15.0-rt"  # Real-time kernel
    osImage: "Ubuntu 22.04.3 LTS"
    containerRuntimeVersion: "containerd://1.7.2"
```

### 2. Trading Application Deployment

```yaml
# trading-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: trading-app
  namespace: quantitative-trading
spec:
  replicas: 3
  selector:
    matchLabels:
      app: trading-app
  template:
    metadata:
      labels:
        app: trading-app
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9090"
    spec:
      nodeSelector:
        node-type: trading-gpu
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values: ["trading-app"]
              topologyKey: kubernetes.io/hostname
      containers:
      - name: trading-app
        image: enterprise/quantitative-trading:2.0.0
        ports:
        - containerPort: 8000
          name: http
        - containerPort: 9090
          name: metrics
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: trading-secrets
              key: database-url
        - name: GPU_ENABLED
          value: "true"
        - name: CUDA_VISIBLE_DEVICES
          value: "0,1"
        resources:
          requests:
            cpu: "8"
            memory: "32Gi"
            nvidia.com/gpu: "2"
          limits:
            cpu: "16"
            memory: "64Gi"
            nvidia.com/gpu: "2"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 60
          periodSeconds: 10
          timeoutSeconds: 5
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 5
        volumeMounts:
        - name: model-storage
          mountPath: /app/models
        - name: data-storage
          mountPath: /app/data
        - name: hugepages-2mi
          mountPath: /dev/hugepages
        securityContext:
          capabilities:
            add: ["IPC_LOCK", "SYS_NICE"]
      volumes:
      - name: model-storage
        persistentVolumeClaim:
          claimName: model-pvc
      - name: data-storage
        persistentVolumeClaim:
          claimName: data-pvc
      - name: hugepages-2mi
        emptyDir:
          medium: HugePages-2Mi
      priorityClassName: trading-critical
```

### 3. High-Performance Service Configuration

```yaml
# trading-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: trading-service
  namespace: quantitative-trading
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: "nlb"
    service.beta.kubernetes.io/aws-load-balancer-backend-protocol: "tcp"
spec:
  type: LoadBalancer
  selector:
    app: trading-app
  ports:
  - name: http
    port: 80
    targetPort: 8000
    protocol: TCP
  - name: metrics
    port: 9090
    targetPort: 9090
    protocol: TCP
  sessionAffinity: ClientIP
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 300
```

### 4. Storage Configuration for High-Frequency Data

```yaml
# storage-class.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: trading-nvme-ssd
provisioner: kubernetes.io/aws-ebs
parameters:
  type: gp3
  iops: "16000"
  throughput: "1000"
  fsType: ext4
  encrypted: "true"
allowVolumeExpansion: true
volumeBindingMode: WaitForFirstConsumer
reclaimPolicy: Retain

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: model-pvc
  namespace: quantitative-trading
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: trading-nvme-ssd
  resources:
    requests:
      storage: 1Ti

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: data-pvc
  namespace: quantitative-trading
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: trading-nvme-ssd
  resources:
    requests:
      storage: 5Ti
```

## Cloud Deployment

### 1. AWS EKS with Optimized Instances

```bash
# Create EKS cluster optimized for trading
eksctl create cluster \
  --name quantitative-trading \
  --version 1.28 \
  --region us-east-1 \
  --with-oidc \
  --managed \
  --nodegroup-name trading-nodes \
  --node-type c6i.16xlarge \
  --nodes 3 \
  --nodes-min 3 \
  --nodes-max 10 \
  --node-ami-family Ubuntu2204 \
  --ssh-access \
  --ssh-public-key trading-key

# Add GPU node group
eksctl create nodegroup \
  --cluster quantitative-trading \
  --name gpu-nodes \
  --node-type p4d.24xlarge \
  --nodes 2 \
  --nodes-min 2 \
  --nodes-max 5 \
  --node-ami-family Ubuntu2204 \
  --ssh-access \
  --ssh-public-key trading-key
```

### 2. Database Setup on AWS

```bash
# Create RDS PostgreSQL for trading data
aws rds create-db-instance \
  --db-instance-identifier trading-postgres \
  --db-instance-class db.r6g.8xlarge \
  --engine postgres \
  --engine-version 15.3 \
  --master-username trading \
  --master-user-password SecurePassword123 \
  --allocated-storage 10000 \
  --storage-type io2 \
  --iops 40000 \
  --storage-encrypted \
  --vpc-security-group-ids sg-trading \
  --db-subnet-group-name trading-subnet-group \
  --backup-retention-period 7 \
  --multi-az \
  --performance-insights-enabled

# Create MemoryDB for Redis
aws memorydb create-cluster \
  --cluster-name trading-cache \
  --node-type db.r6g.2xlarge \
  --num-shards 3 \
  --num-replicas-per-shard 2 \
  --subnet-group-name trading-subnet \
  --security-group-ids sg-trading-cache \
  --parameter-group-name default.memorydb-redis7
```

## Performance Optimization

### 1. CPU Isolation and Affinity

```bash
# CPU isolation for critical trading threads
echo "isolcpus=4-31 nohz_full=4-31 rcu_nocbs=4-31" >> /etc/default/grub
update-grub
reboot

# Set CPU affinity for trading process
taskset -c 4-15 python trading_engine.py &
taskset -c 16-31 python ml_inference.py &
```

### 2. Memory Optimization

```bash
# Configure hugepages for performance
echo 4096 > /proc/sys/vm/nr_hugepages
echo never > /sys/kernel/mm/transparent_hugepage/enabled
echo never > /sys/kernel/mm/transparent_hugepage/defrag

# NUMA optimization
echo 1 > /proc/sys/vm/zone_reclaim_mode
numactl --cpunodebind=0 --membind=0 python trading_engine.py
```

### 3. Network Optimization

```bash
# Network stack tuning for low latency
echo 'net.core.rmem_max = 134217728' >> /etc/sysctl.conf
echo 'net.core.wmem_max = 134217728' >> /etc/sysctl.conf
echo 'net.ipv4.tcp_rmem = 4096 16384 134217728' >> /etc/sysctl.conf
echo 'net.ipv4.tcp_wmem = 4096 65536 134217728' >> /etc/sysctl.conf
echo 'net.core.netdev_max_backlog = 30000' >> /etc/sysctl.conf
echo 'net.ipv4.tcp_congestion_control = bbr' >> /etc/sysctl.conf
sysctl -p
```

## Monitoring and Observability

### 1. Trading-Specific Metrics

```yaml
# prometheus-trading-config.yaml
global:
  scrape_interval: 1s
  evaluation_interval: 1s

rule_files:
  - "trading_alerts.yml"

scrape_configs:
  - job_name: 'trading-app'
    static_configs:
      - targets: ['trading-service:9090']
    scrape_interval: 1s
    metrics_path: /metrics
    
  - job_name: 'market-data'
    static_configs:
      - targets: ['market-data-service:9091']
    scrape_interval: 100ms
    
  - job_name: 'order-management'
    static_configs:
      - targets: ['order-service:9092']
    scrape_interval: 10ms
```

### 2. Critical Alerts

```yaml
# trading-alerts.yml
groups:
- name: trading-critical
  rules:
  - alert: HighLatency
    expr: trading_order_latency_p99 > 0.005
    for: 1s
    labels:
      severity: critical
    annotations:
      summary: "Trading latency exceeded 5ms"
      
  - alert: ModelAccuracyDrop
    expr: ml_model_accuracy < 0.6
    for: 30s
    labels:
      severity: warning
    annotations:
      summary: "ML model accuracy below threshold"
      
  - alert: PositionLimitBreach
    expr: portfolio_position_size > portfolio_max_position
    for: 0s
    labels:
      severity: critical
    annotations:
      summary: "Position limit exceeded"
```

## Security Configuration

### 1. Network Security

```yaml
# network-policy.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: trading-network-policy
  namespace: quantitative-trading
spec:
  podSelector:
    matchLabels:
      app: trading-app
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: trading-gateway
    ports:
    - protocol: TCP
      port: 8000
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: postgres
    ports:
    - protocol: TCP
      port: 5432
  - to: []
    ports:
    - protocol: TCP
      port: 443  # HTTPS for external APIs
```

### 2. Secrets Management

```yaml
# trading-secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: trading-secrets
  namespace: quantitative-trading
type: Opaque
stringData:
  database-url: "postgresql://trading:password@postgres:5432/trading_intelligence"
  bloomberg-api-key: "your-bloomberg-api-key"
  jwt-secret: "your-jwt-secret-key-32-characters"
  encryption-key: "your-encryption-key-32-characters"
```

## Disaster Recovery

### 1. Backup Strategy

```bash
#!/bin/bash
# backup-trading-data.sh

BACKUP_DIR="/backups/trading"
DATE=$(date +%Y%m%d_%H%M%S)

# Database backup
pg_dump -h $DB_HOST -U trading -d trading_intelligence \
  --format=custom --compress=9 \
  > "$BACKUP_DIR/db_backup_$DATE.dump"

# Model backup
tar -czf "$BACKUP_DIR/models_backup_$DATE.tar.gz" /app/models/

# Upload to S3
aws s3 cp "$BACKUP_DIR/" s3://trading-backups/$(date +%Y/%m/%d)/ --recursive

# Clean old backups
find $BACKUP_DIR -name "*.dump" -mtime +7 -delete
find $BACKUP_DIR -name "*.tar.gz" -mtime +7 -delete
```

### 2. Failover Configuration

```yaml
# failover-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: trading-failover
  namespace: quantitative-trading
spec:
  replicas: 1
  selector:
    matchLabels:
      app: trading-failover
  template:
    metadata:
      labels:
        app: trading-failover
    spec:
      containers:
      - name: trading-app
        image: enterprise/quantitative-trading:2.0.0
        env:
        - name: TRADING_MODE
          value: "FAILOVER"
        - name: PRIMARY_ENDPOINT
          value: "trading-service:8000"
        resources:
          requests:
            cpu: "4"
            memory: "16Gi"
          limits:
            cpu: "8"
            memory: "32Gi"
```

This deployment guide provides comprehensive instructions for deploying the Quantitative Trading Intelligence System with institutional-grade performance, security, and reliability requirements.